{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastText_Text_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Rw5IXmCPtQ",
        "colab_type": "text"
      },
      "source": [
        "\"FastText\" Pytorch Implementation of the paper :\n",
        "\n",
        "Bag of Tricks for Efficient Text Classification\n",
        "\n",
        "\"https://arxiv.org/abs/1607.01759\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayg1T_FyCmsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "4827a39b-7f65-482c-c560-bb5b41f60b56"
      },
      "source": [
        "!pip install torchtext --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.5.1+cu101)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTpb7ktMGphn",
        "colab_type": "text"
      },
      "source": [
        "Importing Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUaxfzF6B9xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx2utnaaFDvj",
        "colab_type": "text"
      },
      "source": [
        "Generate Trigrams:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q181bnmFIjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_trigrams(x):\n",
        "    n_grams = set(zip(*[x[i:] for i in range(3)]))\n",
        "    for n_gram in n_grams:\n",
        "        x.append(' '.join(n_gram))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlKHnbnbFVYc",
        "colab_type": "text"
      },
      "source": [
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dprJ5yViFYb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "77430448-8c66-431f-8c7f-a21be079eccd"
      },
      "source": [
        "generate_trigrams(['I ', 'have', 'watched', 'a', 'lot','of', 'TV','in', 'my', 'life'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I ',\n",
              " 'have',\n",
              " 'watched',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'TV',\n",
              " 'in',\n",
              " 'my',\n",
              " 'life',\n",
              " 'a lot of',\n",
              " 'of TV in',\n",
              " 'lot of TV',\n",
              " 'in my life',\n",
              " 'have watched a',\n",
              " 'TV in my',\n",
              " 'watched a lot',\n",
              " 'I  have watched']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo4V3kFNFIn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', preprocessing = generate_trigrams)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHuVkjNGGUt0",
        "colab_type": "text"
      },
      "source": [
        "Loading IMDB dataset and splitinf into test and train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orEI5ly7GjM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cf7e9dde-4887-4a56-d44e-5f60b411111e"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 11.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPvNtxu5GwSN",
        "colab_type": "text"
      },
      "source": [
        "Building Vocabulary and Loading Pre-trained Word Embedings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaFoaEXuHQS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 20_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Y_ksdNHbfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTN4NkNHHd21",
        "colab_type": "text"
      },
      "source": [
        "Model Building:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZXqphaHHgZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FastText(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        \n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "                \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
        "        \n",
        "        #pooled = [batch size, embedding_dim]\n",
        "                \n",
        "        return self.fc(pooled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E2dTddmHqVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XORg4_zWH2Na",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "700ccf59-cf91-420d-cc82-eb0ca8cf6d1b"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,000,301 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2JZZ5gaH67C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "f88db389-9382-4e9d-9c44-9cc97b730afb"
      },
      "source": [
        "#copying Pre-trained vectors to the embeding layers:\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4811,  1.0463,  1.9048,  ..., -1.2565, -0.9292, -1.7791],\n",
              "        [-0.0812, -0.1946, -0.8601,  ..., -1.5480,  0.1313, -2.4751],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 2.0467,  0.6702, -2.2263,  ...,  0.5931,  0.0623,  1.4688],\n",
              "        [ 0.0219, -1.7445, -0.3752,  ..., -0.9976, -0.5819, -0.2369],\n",
              "        [ 0.2297, -0.1678,  0.3385,  ...,  0.6222, -0.9155,  1.6893]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kA5PvDyISAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Put Zeros to padding and Unknown tokens:\n",
        "\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvSOhMdVIl9T",
        "colab_type": "text"
      },
      "source": [
        "Model Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZslC4sAIlhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVSXA9PRIsIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U2cu-b5IxEh",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHBOThk7IsZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 7/10 right, this returns 0.7, NOT 7\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU-XmRg-Isdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_YoMsII2b7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XUSPQknI5fF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "2dbe3243-7cc0-4648-cf25-94f621be31ed"
      },
      "source": [
        "%%time\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.386 | Train Acc: 88.46%\n",
            "\t Val. Loss: 0.419 |  Val. Acc: 85.37%\n",
            "\tTrain Loss: 0.353 | Train Acc: 89.43%\n",
            "\t Val. Loss: 0.430 |  Val. Acc: 85.90%\n",
            "\tTrain Loss: 0.325 | Train Acc: 90.28%\n",
            "\t Val. Loss: 0.445 |  Val. Acc: 86.47%\n",
            "\tTrain Loss: 0.303 | Train Acc: 90.79%\n",
            "\t Val. Loss: 0.457 |  Val. Acc: 86.80%\n",
            "\tTrain Loss: 0.281 | Train Acc: 91.41%\n",
            "\t Val. Loss: 0.469 |  Val. Acc: 87.26%\n",
            "\tTrain Loss: 0.265 | Train Acc: 91.83%\n",
            "\t Val. Loss: 0.487 |  Val. Acc: 87.50%\n",
            "\tTrain Loss: 0.251 | Train Acc: 92.23%\n",
            "\t Val. Loss: 0.498 |  Val. Acc: 88.00%\n",
            "\tTrain Loss: 0.236 | Train Acc: 92.68%\n",
            "\t Val. Loss: 0.511 |  Val. Acc: 88.23%\n",
            "\tTrain Loss: 0.222 | Train Acc: 93.18%\n",
            "\t Val. Loss: 0.526 |  Val. Acc: 88.31%\n",
            "\tTrain Loss: 0.210 | Train Acc: 93.59%\n",
            "\t Val. Loss: 0.538 |  Val. Acc: 88.52%\n",
            "CPU times: user 1min 57s, sys: 18.5 s, total: 2min 15s\n",
            "Wall time: 2min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnqtFreJpDy",
        "colab_type": "text"
      },
      "source": [
        "Test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAhAPrHLJr7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6067896-a102-4f35-8c0f-91c8fb81a9ce"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.410 | Test Acc: 86.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytja5itGJxgS",
        "colab_type": "text"
      },
      "source": [
        "User Input:\n",
        "\n",
        "I have taken some reviews from IMDB both Low rating and High rating for the series \"Breaking Bad\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3kjnIyfKKu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = generate_trigrams([tok.text for tok in nlp.tokenizer(sentence)])\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    if prediction.item() < 0.5:\n",
        "       print(\"Prediction :\", prediction.item(), \"and its a Negative Review\") \n",
        "    else: \n",
        "       print(\"Prediction :\", prediction.item(), \"and its a Positive Review\")\n",
        "    return  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7AWgDjbKZRF",
        "colab_type": "text"
      },
      "source": [
        "Negative Example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lsR4wJSKk_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "79fd5a90-1f8b-45f2-975e-46ecbefd0e6c"
      },
      "source": [
        "predict_sentiment(model, \"I decided to watch this after hearing how good it was - I hadn't watched any of it by the time the last episode had aired.After watching the pilot I thought that the show had potential and was looking forward to getting into a new show - (having just finished Dexter and whilst The Walking Dead and Game of Thrones were both on a break).The short first season spent its time building us up for nothing to actually happen. But as it was quite short and all I had heard was how amazing this show is I opened up Season 2. This was very much of the same - every episode building up to something but not much actually happening.Admittedly Season 3 was a bit better but still quite boring in comparison to many people telling me it's the best TV show ever. In all honesty I haven't bothered with the last 2 seasons as I feel that I have lost several hours of my life watching the first 3 and it's not worth putting the effort in watching the rest. There are plenty of TV shows worth watching before this one. I cannot honestly see why this program has high reviews.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction : 0.4620707631111145 and its a Negative Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ElbsC2DMAKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17c2b53f-decc-4e3e-f852-53bacbb89794"
      },
      "source": [
        "predict_sentiment(model, \"Finally was convinced to watch the show due to all the hype. Was watching with the wife and reached the third season...wow, it felt like forever. After an episode in season 3 i just came out and told the wifey I can't do this anymore, I can't watch this. She looked me in my eyes and the relief I saw was heartwarming, she agreed! I seriously don't know what all that hype was about!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction : 0.1796533465385437 and its a Negative Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0skl7ik9L_Bw",
        "colab_type": "text"
      },
      "source": [
        "Positive Example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQdbIZVqS2V2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e91d237-e4c8-4e24-e499-4bef72d0eb9d"
      },
      "source": [
        "predict_sentiment(model, \"It was very good up to the second season, but the third just spoiled it. Slow paced AF, crappy explanations, ending pretty meh. Random exponential complexity. The multiple worlds stuff, introduced on 3rd season, sucks and really made me lose interest.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction : 0.9168309569358826 and its a Positive Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vssKW2PaS2Y8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee47a206-ac47-4fe6-e59c-a7e124522c16"
      },
      "source": [
        "predict_sentiment(model, \"I highly recommend this show. I don't want to compare it to any other show but it reminded me of Twin Peaks in terms of its darkness. Each episode raises audiences' suspense, which is a good thing. However, you should note every character's name on a paper, prepare a family tree otherwise it will be harder to remember. Great show!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction : 0.9997377991676331 and its a Positive Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nhU1DIVvvrZ",
        "colab_type": "text"
      },
      "source": [
        "Refernce:\n",
        "\n",
        "https://arxiv.org/abs/1607.01759\n",
        "\n",
        "http://bentrevett.com"
      ]
    }
  ]
}